{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @hidden_cell\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the MATH Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Have you ever looked at a Math problem and had no clue on how to solve it? It might be possible that if different types of problems can be clustered into different groups of similar problems, then that might provide some insight on if the problems can be solved in similar ways. Also, when it comes to numbers and math problems, Natural Language Processing (NLP) tools such as Large Language Models (LLMs) can struggle. So, it is interesting to look at a collection of data that might be difficult for LLMs to solve to see if any other insight can be gain from trends within the data. \n",
    "\n",
    "The MATH dataset contains 12,500 problems from different U.S. math competitions such as AMC, AIME, Putnam, and more. Each problem in the dataset contains information including the problem's text, the solution, the subject of the problem, and the difficulty of the problem. The possible subjects for the problems include Prealgebra, Algebra, Number Theory, Counting and Probability, Geometry, Intermediate Algebra,\n",
    "and Precalculus. Here is a distribution of subjects among all the problems:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert code and visual of distribution. Try to hide some of the code i think?? Still figuring out how"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difficulty of the problems range from 1 to 5. This difficulty rating is given by Art of Problem Solving (AoPS). AoPS takes into account that some subjects may be more difficult than others, so the difficulty is in the scope of the subject. Here is a distribution of difficulty among all the problems:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert code and visual of distribution. Try to hide some of the code i think?? Still figuring out how"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the distributions of difficulty for each subject:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert code and visual of distribution. Try to hide some of the code i think?? Still figuring out how"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that overall among all the problems and with each subject, the distribution is not a normal distribution. So, this must be taking into account when doing later analysis of the future outcomes.\n",
    "\n",
    "To analyze the trends, we want to see if the subject of the problem or the difficulty of the problem can be predicted based on the content of the problem statement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some content trends we plan to initially explore are the predictability of the subject or difficulty using content such as the magnitude of numbers, the amount of numbers, or the words in the problem statement. \n",
    "\n",
    "### Exploring Numbers\n",
    "\n",
    "For content like the magnitude of numbers and the amount of numbers, we plan to plot a distribution in order to see if there are clear delinations between the subjects and the difficulties of problems. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for box plot or some other distribution graph for each subject and each difficulty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Words\n",
    "\n",
    "For content like the words, we plan to do an initial analysis by looking at the most common words between subjects and difficulties. After this, we can develop a better hypothesis for the predictabilty, then use a machine learning (ML) approach to determine the predictability of the subject or the difficulty. This ML approach would be through the use of a Multinomial Naive Bayes algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Exploration\n",
    "\n",
    "An introductory tool we can use for exploration of the subjects and difficulties are the most common words in each respective section. If see a some words appearing more than others in the different sections, then we can hypothesize that the section may perform well in getting predicted. When it comes to math problems, there can are lots of stop words and operations such as +, -, /, *, ^, etc. These elements may be useful or harmful for the prediction of the section, so we can explore the diversity between the most common words in the section with and without these elements.\n",
    "\n",
    "Here is the most common words per section using all of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input code for most common 5 or 10 words from each subject category and for each difficulty category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the most common words per section with stopwords removed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input code for most common 5 or 10 words from each subject category and for each difficulty category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the most common words per section with operations removed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input code for most common 5 or 10 words from each subject category and for each difficulty category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the most common words per section with both removed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input code for most common 5 or 10 words from each subject category and for each difficulty category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Analysis and Hypotheses\n",
    "\\* Analysis once data is seen *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomial Naive Bayes (MNB)\n",
    "\n",
    "A Multinomial Naive Bayes model is a probabilistic NLP model that takes in tokens and their counts, then calculates the probability for outcomes to classify discrete classification problems. The probability for the different tokens are classified using the formula.\n",
    "\n",
    "$$\n",
    "P(A|B)=\\frac{P(B|A)*P(A)}{P(B)}\n",
    "$$\n",
    "\n",
    "In order to set up the tokens and the counts for the Multinomial Naive Bayes model, we used a count vectorizer to turn the math problem statements into token counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for setting up Count Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the token vectorizer, we had the flexibility to choose the minimum amount of problems that a token had to be in and the maximum number of problems to be in. We worked on hypertuning the parameters from a minimum problem count between *insert min and max* to a maximum problem count between *insert min and max*. After hypertuning these parameters and using the counts on the MNB model, we ended up with the best parameters being *insert best* for the subjects and *insert* for the difficulties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the code for the best MNB model on the subjects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for MNB model with the best parameters on subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the code for the best MNB model on the difficulties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for MNB model with the best parameters on difficulties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\* Analysis of confusion matrices *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
